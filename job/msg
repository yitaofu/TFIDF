cd /home/rank/zhangyong/tfidf/work; rm -rf tfidf.zip; zip -r tfidf.zip *; cd -;
  adding: err (stored 0%)
  adding: job_filter.xml (deflated 60%)
  adding: job.xml (deflated 76%)
  adding: msg
	zip warning:  file size changed while zipping msg
 (deflated 32%)
/home/rd/fuyitao/TFIDF/tfidf/job
/home/rd/share/hadoop/bin/hadoop fs -rmr /data/archive/app_oeudjgn5872a7c3aaa54_datamine/tfidf/cid_term-tmp;
/home/rd/share/hadoop/bin/hadoop jar /home/rd/share/hadoop/contrib/streaming/hadoop-streaming-1.1.2.jar -archives /home/rank/zhangyong/tfidf/work/tfidf.zip'#work' -mapper "sh -x work/cid_term_map.sh" -reducer "sh -x work/cid_term_reduce.sh" -input "/user/rank/title_seg2/part-*" -output "/data/archive/app_oeudjgn5872a7c3aaa54_datamine/tfidf/cid_term-tmp" -partitioner "org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner" -jobconf stream.map.output.field.separator="	" -jobconf stream.num.map.output.key.fields="3" -jobconf map.output.key.field.separator="	" -jobconf num.key.fields.for.partition="3" -jobconf mapred.reduce.tasks="997" -jobconf mapred.job.map.capacity="32" -jobconf mapred.job.reduce.capacity="32" -jobconf mapred.compress.map.output="false" -jobconf mapred.output.compress="false" -jobconf mapred.job.priority="NORMAL" -jobconf mapred.job.queue.name="rank" -jobconf stream.memory.limit="1024" -jobconf mapred.map.capacity.per.tasktracker="7" -jobconf mapred.reduce.capacity.per.tasktracker="7" -jobconf mapred.job.name="cid_term" 1>/home/rank/zhangyong/tfidf/log/cid_term.msg 2>/home/rank/zhangyong/tfidf/log/cid_term.err
date | mail -s 'cid_term failed' zhangyong@weidian.com
